{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Theory Questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbor Classiﬁcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume that you have a large training dataset. Specify a disadvantage of the kNearest Neighbor method when using it during testing. State also your reason about your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Answer: Larger datasets cost more time and memory than smaller ones during testing because at the testing process algoritm has to scan and store more data for prediction.This is a disadvange of kNearest Neighbor algoritm for large training datasets.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a 1-Dimensional classiﬁcation dataset in which the 1-Nearest Neighbors method always gives a leave-one out cross validation error value of 1 (In other words, the method can’t guess correct class for a speciﬁc point in the dataset ). State also a proper explanation about your reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Answer: There can two possible reason for model's low accuracy,One is that 1 dimensional dataset's dimension size is too low to fit a model and this cause underfitting.Second is that k hyperparameter (K-nearest) is too low to predict true value.It must be increased a proper value for more accurate predictions.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Assume that you have the following training set of positive (+), negative (-) instances and a single test instance (o) in the ﬁgure below (Figure 1). Assume also that the Euclidean metric is used for measuring the distance between instances. Finally consider that every nearest neighbor instance aﬀects the ﬁnal vote equally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• What is the class appointed to the test instance for K=1? State also reason behind your answer. \n",
    "\n",
    "<font color=red>Answer:  Appointed class is negative because the first nearest point is negative.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• What is the class appointed to the test instance for K=3? State also reason behind your answer.\n",
    "\n",
    "<font color=red>Answer: Appointed class for 3 nearest neighbor is also negatif because all neighbor's weight are equal and negative neighbors outnumber.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• What is the class appointed to the test instance for K=5? State also reason behind your answer.\n",
    "\n",
    "<font color=red>Answer: Appointed class for 3 nearest neighbor is positive because all neighbor's weight are equal and positive neighbors outnumber.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Fill the blanks with T (True) or F (False) for the statements below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• If all instances of the data have the same scale then k-Nearest Neighbor’s performance increases drastically. (<font color=red>F</font> ) \n",
    "\n",
    "• While k-Nearest Neighbor performs well with a small number of input variables, it’s performance decreases when the number of inputs becomes large. (<font color=green>T</font>) \n",
    "\n",
    "• k-Nearest Neighbor makes no assumption about the functional form of the problem it handles. (<font color=green>T</font>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume that you have ﬁve students have registered to a class and the class have a midterm and the ﬁnal exam. You have obtained a set of their marks on two exams, which is in the table below:\n",
    "\n",
    "You plan to a model which form’s is fθ(x) = θ0 + θ1x1 + θ2x2 for ﬁtting the data above. The x1 shows midterm exam score while x2 shows square of the midterm score. Besides you plan to use feature scaling (using divide operation by the ”maxmin”, or range, of a feature) and mean normalization. What is the normalized value of the feature x(4) 2 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Answer: 0.38</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Considering the ﬁgure below (Figure 2), which of the oﬀsets used in linear regressions least square line ﬁt? Assume that horizontal axis represents independent variable and vertical axis represents dependent variable. State your answer with your proper explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Answer: We have to use vertical offsets for linear regressions least square.In this case vertical distance represent our residuals.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Considering the table below (Table 1), consisting of four training examples:\n",
    "Assume that you are trying to ﬁt the data above to the linear regression model fθ(x) = θ0 + θ1x1. Find the θ0 and θ1 values by using closed form solution (θ = (XTX)−1XTy). Also state dimension values of X, y and θ matrices. Finally show your calculations step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Answer: In order to find thetas we have to do below process</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A^T*A*x=A^T*B\n",
    "import numpy as np\n",
    "aTranspose=np.array([1,2,4,0]).reshape(4,1)\n",
    "aTa=np.matmul(np.array([1,2,4,0]),aTranspose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A^T*A*x\n",
    "aTa\n",
    "21*x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A^T*B\n",
    "b=np.array([0.5,1,2,0]).reshape(4,1)\n",
    "aBa=np.matmul(np.array([1,2,4,0]),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aBa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21x1=10.5\n",
    "\n",
    "x1 is 0.5 and x0 is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. State a valid reason for feature scaling and explain why it is a valid reason with respect to your reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Answer: In many machine learning algoritms we use Euclidian distance.If we don't normalize our dataset this formula can give misleading outcomes.Big values dominate small values and small features become meaningless eventhough they can be quite significant.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Definition:Creating a user-based movie rating prediction system by using KNN and weighted KNN algoritm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "os.chdir(r\"E:\\Masaüstü\\bbm409-assignment1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing needed data\n",
    "mv=pd.read_csv(\"movies.csv\").copy()\n",
    "rt=pd.read_csv(\"ratings_train.csv\").copy()\n",
    "myTest=pd.read_csv(\"ratings_test_without_gt_new.csv\")\n",
    "myTest2=myTest[myTest[\"rating\"]!=-1]#feature çıkartmak için convert edilmesi gereken test datası \n",
    "myTest=myTest[myTest[\"rating\"]==-1]#predict edilmesi istenen test değerleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847434962</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1305696483</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1455209816</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp             title  \\\n",
       "0       1        1     4.0   964982703  Toy Story (1995)   \n",
       "1       5        1     4.0   847434962  Toy Story (1995)   \n",
       "2      15        1     2.5  1510577970  Toy Story (1995)   \n",
       "3      17        1     4.5  1305696483  Toy Story (1995)   \n",
       "4      18        1     3.5  1455209816  Toy Story (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "4  Adventure|Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### combining movies.csv and ratings_train.csv with respect to movieıD\n",
    "#combined data\n",
    "new=pd.merge(rt, mv, on='movieId', how='inner')\n",
    "new=pd.merge(rt, mv, on='movieId', how='inner')\n",
    "new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method creates feature matrix for training data, returns training Data's feature matrix and trainingDataUsers matrix \n",
    "#parameters are combined data and movies.csv. Use only for training data\n",
    "def dataConverter(new,mv):\n",
    "    \n",
    "    new[\"isAd\"]=[1 if \"Adventure\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isAn\"]=[1 if \"Animation\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isCh\"]=[1 if \"Children\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isCo\"]=[1 if \"Comedy\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isFa\"]=[1 if \"Fantasy\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isRo\"]=[1 if \"Romance\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isHo\"]=[1 if \"Horror\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isAc\"]=[1 if \"Action\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isDr\"]=[1 if \"Drama\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isCr\"]=[1 if \"Crime\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isTh\"]=[1 if \"Thriller\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isMy\"]=[1 if \"Mystery\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isSc\"]=[1 if \"Sci-Fi\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isWa\"]=[1 if \"War\" in i else 0 for i in new[\"genres\"]]\n",
    "    new[\"isDo\"]=[1 if \"Documentary\" in i else 0 for i in new[\"genres\"]]\n",
    "    new2=new[new.columns[6:]].copy()\n",
    "    new2[\"userId\"]=new[\"userId\"]\n",
    "    trainingData=new2.groupby('userId').sum()\n",
    "    trainingDataUsers=trainingData.index.to_numpy()\n",
    "    trainingData=trainingData.to_numpy()\n",
    "    return trainingData,trainingDataUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method creates feature matrix for test data, returns test Data's feature matrix and test DataUsers matrix \n",
    "#parameters are convert edilmesi gereken test datası(myTest2) and movies.csv. Use only for training data\n",
    "def testDataConverter(new1,mv):\n",
    "    new=new1[new1[\"rating\"]!=-1]\n",
    "    new1=new1[new1[\"rating\"]==-1]\n",
    "    new=pd.merge(new, mv, on='movieId', how='inner')\n",
    "    new[\"isAd\"]=[1 if \"Adventure\" in i else 0 for i in new.genres]\n",
    "    new[\"isAn\"]=[1 if \"Animation\" in i else 0 for i in new.genres]\n",
    "    new[\"isCh\"]=[1 if \"Children\" in i else 0 for i in new.genres]\n",
    "    new[\"isCo\"]=[1 if \"Comedy\" in i else 0 for i in new.genres]\n",
    "    new[\"isFa\"]=[1 if \"Fantasy\" in i else 0 for i in new.genres]\n",
    "    new[\"isRo\"]=[1 if \"Romance\" in i else 0 for i in new.genres]\n",
    "    new[\"isHo\"]=[1 if \"Horror\" in i else 0 for i in new.genres]\n",
    "    new[\"isAc\"]=[1 if \"Action\" in i else 0 for i in new.genres]\n",
    "    new[\"isDr\"]=[1 if \"Drama\" in i else 0 for i in new.genres]\n",
    "    new[\"isCr\"]=[1 if \"Crime\" in i else 0 for i in new.genres]\n",
    "    new[\"isTh\"]=[1 if \"Thriller\" in i else 0 for i in new.genres]\n",
    "    new[\"isMy\"]=[1 if \"Mystery\" in i else 0 for i in new.genres]\n",
    "    new[\"isSc\"]=[1 if \"Sci-Fi\" in i else 0 for i in new.genres]\n",
    "    new[\"isWa\"]=[1 if \"War\" in i else 0 for i in new.genres]\n",
    "    new[\"isDo\"]=[1 if \"Documentary\" in i else 0 for i in new.genres]\n",
    "    new2=new[new.columns[5:]].copy()\n",
    "    new2[\"userId\"]=new[\"userId\"]\n",
    "    testData=new2.groupby('userId').sum()\n",
    "    userIDVector=testData.index.to_numpy()\n",
    "    testData=testData.to_numpy()\n",
    "    return testData,userIDVector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method create and return a dataframe thats colums are moviesIds and rows are usersIds.Parameter is combined data.\n",
    "#This basicly our known target\n",
    "def trainTargetConverter(new):\n",
    "    dic={}\n",
    "    for i in new.index:\n",
    "        if(new[\"userId\"][i]  not in dic.keys()):\n",
    "            dic[new[\"userId\"][i]]={new[\"movieId\"][i]:new[\"rating\"][i]}\n",
    "        else:\n",
    "              dic[new[\"userId\"][i]].update({new[\"movieId\"][i]:new[\"rating\"][i]})\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(dic) \n",
    "    df=df.T\n",
    "    df=df.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "    df=df.sort_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning train trainUser test testUser\n",
    "trainingData,trainingDataUsers=dataConverter(new,mv)\n",
    "testData,testDataUsers=testDataConverter(myTest2,mv)\n",
    "trainTarget=trainTargetConverter(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and Knn methods\n",
    "\n",
    "from numpy import linalg as LA\n",
    "def fitMethod(train,test,kPara,trainTarget,trainingDataUsers,testDataUsers):\n",
    "    #cosine based similarity used\n",
    "    similarityMatrix=((np.matmul(train, test.T))/(LA.norm(train)*LA.norm(test)))\n",
    "    return KNNMethod(similarityMatrix,trainTarget,kPara,trainingDataUsers,testDataUsers)\n",
    "\n",
    "\n",
    "#This method returns a dataframe that colums are all movies in the movies.csv and rows are testusersId\n",
    "#return predictedValues\n",
    "def KNNMethod(similarityMatrix,trainTarget,kPara,trainingDataUsers,testDataUsers):\n",
    "    sm=similarityMatrix.copy()\n",
    "    sm=pd.DataFrame(sm,index=trainingDataUsers,columns=testDataUsers)\n",
    "    predictValues=[]\n",
    "    dic={}\n",
    "    for i in sm.columns:\n",
    "        col=i\n",
    "        sm=sm.sort_values(by=col, ascending=False)\n",
    "        values=sm.index[0:kPara]\n",
    "        dic[i]={x:(sum(trainTarget.loc[values,x])/len(values)) for x in trainTarget.columns}\n",
    "\n",
    "    predictValues=pd.DataFrame(dic).T\n",
    "   \n",
    "    return predictValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method calculates MAE.Parameters ara trainTarget and predictedValues and only for known target\n",
    "def testMethod(trainTarget,predictValues):\n",
    "    sumValue=0\n",
    "    for i in predictValues.index:\n",
    "        for y in predictValues.columns:\n",
    "            sumValue=abs((trainTarget[y][i])-(predictValues[y][i]))+sumValue\n",
    "        \n",
    "    MAE=(1/(len(predictValues)*len(trainTarget.columns)))*sumValue\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crossValidation method is only for TESTING, it cant't be used in unknown targets.It returns average of number of error\n",
    "def crossValidation(kFold,trainingData,kPara,trainTarget,trainingDataUsers):#trainingData is data ,k fold\n",
    "    \n",
    "    data=trainingData.copy()\n",
    "    data2=trainingDataUsers.copy()\n",
    "    folds = np.array_split(data, kFold)\n",
    "    foldsUsers=np.array_split(data2,kFold)\n",
    "    listOfAccu=[]\n",
    "    for i in range(kFold):\n",
    "        tempTrain=folds.copy()\n",
    "        tempTrainUser=foldsUsers.copy()\n",
    "        test=folds[i].copy()\n",
    "        testDataUsers=foldsUsers[i].copy()\n",
    "        del tempTrain[i]\n",
    "        del tempTrainUser[i]\n",
    "        train=np.concatenate(tempTrain, axis=0).copy()\n",
    "        trainingDataUsers=np.concatenate(tempTrainUser, axis=0).copy()\n",
    "        predictValues=fitMethod(train,test,kPara,trainTarget,trainingDataUsers,testDataUsers)\n",
    "        listOfAccu.append(testMethod(trainTarget,predictValues))\n",
    "    print(\"MAE for k-fold \",kFold,\" \",sum(listOfAccu)/kFold)  \n",
    "    return sum(listOfAccu)/kFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict method takes userId and Movie tuple or list and predictedValues as parameters return and print userId and rating\n",
    "def predictMethod(userAndMovie,predictedValues):\n",
    "    listOfPrediction=[]\n",
    "    for i in userAndMovie:\n",
    "        print(i[0],\",\",predictedValues[i[1]][i[0]])\n",
    "        listOfPrediction.append([i[0],predictedValues[i[1]][i[0]]])\n",
    "    return listOfprediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#less test data is used in this cell due to the time issues. k parameter is 3\n",
    "predicted=fitMethod(trainingData[20:],trainingData[0:20],3,trainTarget,trainingDataUsers[20:],trainingDataUsers[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.966319</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>2.04735</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.013669</td>\n",
       "      <td>2.763638</td>\n",
       "      <td>3.299652</td>\n",
       "      <td>...</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.54735</td>\n",
       "      <td>3.449124</td>\n",
       "      <td>2.782457</td>\n",
       "      <td>2.829807</td>\n",
       "      <td>2.579776</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.966319</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>2.04735</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.013669</td>\n",
       "      <td>2.763638</td>\n",
       "      <td>3.299652</td>\n",
       "      <td>...</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.966319</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>2.04735</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.013669</td>\n",
       "      <td>2.763638</td>\n",
       "      <td>3.299652</td>\n",
       "      <td>...</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "      <td>3.144321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.54735</td>\n",
       "      <td>3.449124</td>\n",
       "      <td>2.782457</td>\n",
       "      <td>2.829807</td>\n",
       "      <td>2.579776</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "      <td>2.960459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8904 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1         2         3         4        5         6         7       \\\n",
       "4   3.666667  2.833333  2.966319  3.144321  2.04735  3.500000  2.833333   \n",
       "7   4.000000  2.833333  2.833333  2.960459  2.54735  3.449124  2.782457   \n",
       "10  3.666667  2.833333  2.966319  3.144321  2.04735  3.500000  2.833333   \n",
       "16  3.666667  2.833333  2.966319  3.144321  2.04735  3.500000  2.833333   \n",
       "19  4.000000  2.833333  2.833333  2.960459  2.54735  3.449124  2.782457   \n",
       "\n",
       "      8         9         10      ...    193565    193567    193571    193573  \\\n",
       "4   3.013669  2.763638  3.299652  ...  3.144321  3.144321  3.144321  3.144321   \n",
       "7   2.829807  2.579776  3.500000  ...  2.960459  2.960459  2.960459  2.960459   \n",
       "10  3.013669  2.763638  3.299652  ...  3.144321  3.144321  3.144321  3.144321   \n",
       "16  3.013669  2.763638  3.299652  ...  3.144321  3.144321  3.144321  3.144321   \n",
       "19  2.829807  2.579776  3.500000  ...  2.960459  2.960459  2.960459  2.960459   \n",
       "\n",
       "      193579    193581    193583    193585    193587    193609  \n",
       "4   3.144321  3.144321  3.144321  3.144321  3.144321  3.144321  \n",
       "7   2.960459  2.960459  2.960459  2.960459  2.960459  2.960459  \n",
       "10  3.144321  3.144321  3.144321  3.144321  3.144321  3.144321  \n",
       "16  3.144321  3.144321  3.144321  3.144321  3.144321  3.144321  \n",
       "19  2.960459  2.960459  2.960459  2.960459  2.960459  2.960459  \n",
       "\n",
       "[5 rows x 8904 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718745701427801\n"
     ]
    }
   ],
   "source": [
    "#MAE for k hyperparameter =3\n",
    "MAE=testMethod(trainTarget,predicted)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for  3  hyperparameter 0.718745701427801\n",
      "MAE for  4  hyperparameter 0.7062708369633199\n",
      "MAE for  5  hyperparameter 0.6368167278080952\n",
      "MAE for  6  hyperparameter 0.6030906380597183\n",
      "MAE for  7  hyperparameter 0.557272431223616\n",
      "MAE for  8  hyperparameter 0.5363309773322302\n",
      "MAE for  9  hyperparameter 0.5261050499817567\n",
      "MAE for  10  hyperparameter 0.5329945908934768\n"
     ]
    }
   ],
   "source": [
    "#trying different k parameter\n",
    "for i in range(3,11):\n",
    "    predicted=fitMethod(trainingData[20:],trainingData[0:20],i,trainTarget,trainingDataUsers[20:],trainingDataUsers[0:20])\n",
    "    MAE=testMethod(trainTarget,predicted)\n",
    "    print(\"MAE for \",i,\" hyperparameter\",MAE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for k-fold  5   0.4845092106479411\n"
     ]
    }
   ],
   "source": [
    "#testing algoritm accuracy with cross validation kFold is 5 k parameter is 9.\n",
    "#less training data is used in this test due to the time issue\n",
    "predictedCv=crossValidation(5,trainingData[0:50],9,trainTarget,trainingDataUsers[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for k-fold  5   0.48406924613027585\n"
     ]
    }
   ],
   "source": [
    "#for k=10 hyperparameter\n",
    "predictedCv=crossValidation(5,trainingData[0:50],10,trainTarget,trainingDataUsers[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weightedFitMethod and WeightedKnn method takes same parameters and return same values like normal fit and knn method.\n",
    "#but in this knnMethod neighbors weight is like below\n",
    "# (k is hyperparameter k) 1.neighbor*k+2.neighbor*k-1+....+k.neighbor*1\n",
    "def weightedFitMethod(train,test,kPara,trainTarget,trainingDataUsers,testDataUsers):\n",
    "    similarityMatrix=((np.matmul(train, test.T))/(LA.norm(train)*LA.norm(test)))\n",
    "    return weightedKNNMethod(similarityMatrix,trainTarget,kPara,trainingDataUsers,testDataUsers)\n",
    "    \n",
    "def weightedKNNMethod(similarityMatrix,trainTarget,kPara,trainingDataUsers,testDataUsers):\n",
    "    sm=similarityMatrix.copy()\n",
    "    sm=pd.DataFrame(sm,index=trainingDataUsers,columns=testDataUsers)\n",
    "    predictValues=[]\n",
    "    dic={}\n",
    "    kParaList=[k for k in range(kPara,0,-1)]\n",
    "    sumKPara=sum(kParaList)\n",
    "    for i in sm.columns:\n",
    "        col=i\n",
    "        sm=sm.sort_values(by=col, ascending=False)\n",
    "        values=sm.index[0:kPara]\n",
    "        mapped=zip(values,kParaList)\n",
    "        mapped=[list(i) for i in mapped]\n",
    "        dictionary={x[0]:x[1] for x in mapped}\n",
    "        \n",
    "        \n",
    "        copyTrainTarget=trainTarget.loc[values,:].copy()\n",
    "        \n",
    "        copyTrainTarget=copyTrainTarget.mul(kParaList, axis=0)\n",
    "            \n",
    "        dic[i]={x:(sum(copyTrainTarget.loc[values,x])/sumKPara) for x in trainTarget.columns}\n",
    "        \n",
    "    \n",
    "    predictValues=pd.DataFrame(dic).T\n",
    "   \n",
    "    return predictValues\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for  3  hyperparameter 0.6990316897214891  in weighted KNN\n",
      "MAE for  4  hyperparameter 0.6996309669354022  in weighted KNN\n",
      "MAE for  5  hyperparameter 0.6771204180778738  in weighted KNN\n",
      "MAE for  6  hyperparameter 0.6549371969429224  in weighted KNN\n",
      "MAE for  7  hyperparameter 0.6292831653646285  in weighted KNN\n",
      "MAE for  8  hyperparameter 0.6068984779981725  in weighted KNN\n",
      "MAE for  9  hyperparameter 0.5895159628926648  in weighted KNN\n",
      "MAE for  10  hyperparameter 0.5780313240983389  in weighted KNN\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,11):\n",
    "    predictedWe=weightedFitMethod(trainingData[20:],trainingData[0:20],i,trainTarget,trainingDataUsers[20:],trainingDataUsers[0:20])\n",
    "    MAE=testMethod(trainTarget,predictedWe)\n",
    "    print(\"MAE for \",i,\" hyperparameter\",MAE,\" in weighted KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to test results the best k hyperparameter is 9 ,the best knn algoritm is simple knn (not weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
